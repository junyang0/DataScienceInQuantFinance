{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import copy \n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# Neural Network-Based Dollar-Neutral Trading Strategy\n\n**Course**: DSA5205 - Data Science in Quantitative Finance  \n**Institution**: National University of Singapore\n\n## Notebook Overview\n\nThis notebook implements and evaluates three neural network architectures for systematic trading:\n\n1. **Data Loading**: US large-cap stocks (22 tickers) + macro indicators (7 series)\n2. **Model Training**: MLP (baseline), LSTM (temporal), CNN-LSTM (hybrid)\n3. **Backtesting**: Realistic transaction costs (10 bps), dollar-neutral constraint\n4. **Evaluation**: Comprehensive performance metrics, statistical significance, regime analysis\n\n**Key Results** (Out-of-Sample 2015-2025):\n- CNN-LSTM Sharpe: **0.970** vs SPY: 0.874\n- Max Drawdown: **-21.02%** vs SPY: -31.83% (34% lower)\n- Statistical Significance: **NOT significant** (p=0.472, bootstrap N=10,000)\n\n**Methodology Highlights**:\n- Time-respecting validation (strict chronological splits)\n- Domain-expert hyperparameters (validated via Bayesian optimization)\n- 5-model ensemble averaging\n- Yearly retraining to adapt to regime changes",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 1. Setup and Configuration\n\nInitialize random seeds for reproducibility and import required libraries.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 2. Data Loading and Preprocessing\n\nLoad stock price data for 22 US large-cap stocks across 5 sectors:\n- **Technology**: AAPL, MSFT, GOOGL, AMZN, NVDA\n- **Financials**: JPM, BAC, GS, C\n- **Healthcare**: JNJ, PFE, MRK, UNH\n- **Energy**: XOM, CVX, COP, SLB\n- **Industrials/Consumer**: BA, CAT, MMM, DIS, NKE\n\n**Data Specification**:\n- Source: Yahoo Finance (yfinance)\n- Period: January 2008 - October 2025 (17+ years)\n- Frequency: Weekly (Friday close)\n- Treatment: Adjusted for splits and dividends",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1d/lth_8mwx6hn_48s9f9p9lpvc0000gn/T/ipykernel_49365/2975323493.py:15: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  return yf.download(tickers, start=start_date, end=end_date)\n",
      "[*********************100%***********************]  22 of 22 completed\n"
     ]
    }
   ],
   "source": [
    "tickers = [\n",
    "    # Mega-cap Tech (keep for comparison)\n",
    "    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"NVDA\",\n",
    "    # Financials\n",
    "    \"JPM\", \"BAC\", \"GS\", \"C\", \n",
    "    # Healthcare\n",
    "    \"JNJ\", \"PFE\", \"MRK\", \"UNH\", \n",
    "    # Energy\n",
    "    \"XOM\", \"CVX\", \"COP\", \"SLB\",\n",
    "    # Industrials / Consumer\n",
    "    \"BA\", \"CAT\", \"MMM\", \"DIS\", \"NKE\",    \n",
    "]\n",
    "\n",
    "def fetch_stock_data(tickers, start_date=\"2008-01-01\", end_date=\"2025-10-01\"): \n",
    "    return yf.download(tickers, start=start_date, end=end_date) \n",
    "\n",
    "yfinance_df  = fetch_stock_data(tickers).dropna(how='any',axis=1).dropna(how='any',axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 4. Backtesting with Transaction Costs\n\nImplement realistic backtesting framework:\n\n**Transaction Cost Model**:\n- Rate: 10 basis points (0.001) per trade\n- Applied to turnover (sum of absolute weight changes)\n- Industry-standard assumption for liquid large-caps\n\n**Performance Metrics Calculated**:\n1. **Return metrics**: Annualized return (gross & net), volatility\n2. **Risk-adjusted**: Sharpe ratio, Sort ino ratio, Calmar ratio\n3. **Risk metrics**: Maximum drawdown, win rate\n4. **Trading metrics**: Average turnover, total TC cost, TC impact on Sharpe\n\n**Benchmark**: SPY ETF (S&P 500 buy-and-hold) over identical period",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Performance Visualization\n\nGenerate publication-quality visualizations for result analysis:\n\n**Plot Set 1** (performance_plots_1.png):\n1. Cumulative returns: All strategies vs SPY benchmark\n2. CNN-LSTM vs SPY focused comparison\n3. Rolling 52-week Sharpe ratio evolution\n4. Drawdown analysis over time\n\n**Plot Set 2** (performance_plots_2.png):\n1. Weekly returns distribution (CNN-LSTM vs SPY)\n2. Portfolio turnover over time (12-week moving average)\n3. Transaction cost impact on Sharpe ratios\n4. Cumulative transaction costs\n\n**Plot Set 3** (oos_r2_analysis.png):\n1. Rolling out-of-sample R² (52-week window)\n2. Overall OOS R² by model\n\n**Key Insight**: Negative R² values indicate models don't predict individual stock returns well—performance stems from portfolio construction (cross-sectional allocation) rather than forecasting accuracy.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Statistical Significance and Regime Analysis\n\nAssess robustness through rigorous statistical testing:\n\n**Bootstrap Confidence Intervals** (N=10,000):\n- Construct 95% confidence intervals for Sharpe ratios\n- Test statistical significance of CNN-LSTM vs SPY difference\n- Account for finite-sample uncertainty\n\n**Regime-Specific Analysis**:\n1. **Pre-COVID Bull** (Oct 2015 - Feb 2020): Strategy performance in stable growth markets\n2. **COVID Crisis** (Mar 2020 - Dec 2020): Performance during market stress\n3. **Recovery & Rates** (Jan 2021 - Sep 2025): Behavior in volatile rate environment\n\n**Year-over-Year Analysis**:\n- Annual return comparison (2016-2025)\n- Win rate calculation (years outperforming SPY)\n\n**Critical Finding**: Despite point estimate outperformance (Sharpe 0.970 vs 0.874), wide confidence intervals and p=0.472 indicate the difference is **NOT statistically significant** at conventional levels. Performance is better characterized as comparable to passive indexing with enhanced risk management.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "# Model Architecture and Training Setup\n\nThis section defines:\n1. **Neural Network Architectures**: MLP (baseline), LSTM (temporal), CNN-LSTM (hybrid)\n2. **Loss Function**: Sharpe ratio maximization with transaction cost penalty\n3. **Training Infrastructure**: Rolling window validation, ensemble averaging, early stopping\n4. **Domain-Expert Hyperparameters**: Validated in Section 8 of FINAL_REPORT.md\n   - CNN channels: 16 (cross-sectional feature learning)\n   - Dropout: 0.1 (regularization with BatchNorm)\n   - TC Lambda: 0.1 (transaction cost penalty weight)\n   - Learning rate: 1e-4 (Adam optimizer)\n\n**Key Methodological Choices**:\n- Dollar-neutral constraint (zero market beta exposure)\n- 25-week lookback window (≈6 months of price history)\n- Yearly retraining to adapt to regime changes\n- 5-model ensemble to reduce variance",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Get Monday open and Friday close within each week\nweekly_open = yfinance_df[\"Open\"].resample(\"W-FRI\").first()\nweekly_close = yfinance_df[\"Close\"].resample(\"W-FRI\").last()\n\n# Compute weekly return: Monday open → Friday close\ny = (weekly_close / weekly_open - 1).shift(-1).dropna()\n\n# Weekly features (Friday snapshot)\nX = yfinance_df.resample(\"W-FRI\").last().dropna()\n\ntickers = ['IEF', 'TLT', 'SHY', 'GLD', 'USO', '^VIX', 'DX-Y.NYB']  # DXY ticker on Yahoo\nmacro_data = yf.download(tickers, start='2010-01-01', end='2025-10-31')['Close']\nmacro_weekly = macro_data.resample(\"W-FRI\").last().dropna()\nX = pd.concat([X, macro_weekly], axis=1).dropna()\n\n# Align features and target\ncommon = X.index.intersection(y.index)\nX = X.loc[common]\ny = y.loc[common]\n\n# ============================================================================\n# STATIC HYPERPARAMETERS (Domain-Expert Selection)\n# ============================================================================\n# These parameters were validated in Section 8 of FINAL_REPORT.md\n# Static domain-expert selection outperformed both standard and robust optimization\nSTATIC_CNN_CHANNELS = 16\nSTATIC_DROPOUT = 0.1\nSTATIC_TC_LAMBDA = 0.1\nSTATIC_LR = 0.0001\n\nclass TCNBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, dilation, dropout=0.1):\n        super().__init__()\n        self.conv1 = nn.Conv1d(\n            in_channels, out_channels, kernel_size,\n            padding=(kernel_size-1)*dilation, dilation=dilation\n        )\n        self.bn1 = nn.BatchNorm1d(out_channels)\n        self.act1 = nn.GELU()\n        self.dropout = nn.Dropout(dropout)\n        self.residual = nn.Conv1d(in_channels, out_channels, 1) \\\n                        if in_channels != out_channels else nn.Identity()\n\n    def forward(self, x):\n        # x: (batch, channels, seq_len)\n        out = self.conv1(x)\n        out = out[:, :, :x.size(2)]  # crop to original seq_len\n        out = self.bn1(out)\n        out = self.act1(out)\n        out = self.dropout(out)\n        res = self.residual(x)\n        return out + res\n\nclass TimeSeriesDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = X\n        self.y = y\n        # ensure y is always 2D: (num_samples, n_outputs)\n        if self.y.ndim == 1:\n            self.y = self.y[:, None]\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\n\ndef make_dollar_neutral(x):\n    # x: (batch, n_outputs)\n    return x - x.mean(dim=1, keepdim=True)\n\nclass CNNLSTM2D(nn.Module):\n    \"\"\"CNN-LSTM with Static (Domain-Expert) hyperparameters\"\"\"\n    def __init__(self, n_features, n_outputs, lookback):\n        super().__init__()\n        self.conv = nn.Conv2d(\n            in_channels=1,       \n            out_channels=STATIC_CNN_CHANNELS,  # 16 (domain-expert)\n            kernel_size=(1, 5),  \n            padding=(0, 2)       \n        )\n        self.bn = nn.BatchNorm2d(STATIC_CNN_CHANNELS)\n        self.act = nn.GELU()\n\n        self.lstm = nn.LSTM(\n            input_size=n_features + STATIC_CNN_CHANNELS,\n            hidden_size=64,\n            num_layers=1,\n            batch_first=True,\n            dropout=STATIC_DROPOUT  # 0.1 (domain-expert)\n        )\n        self.fc = nn.Linear(64, n_outputs)\n        self.dropout = nn.Dropout(STATIC_DROPOUT)  # 0.1 (domain-expert)\n\n    def forward(self, x):\n        # x: (batch, seq_len, n_features)\n        B, T, F = x.shape\n\n        # Conv2d expects (B, C, H, W) → here H=1, W=features\n        x_in = x.unsqueeze(1)  # (B, 1, T, F)\n        x_cnn = self.act(self.bn(self.conv(x_in)))  # (B, 16, T, F)\n        # Pool along features (optional)\n        x_cnn = x_cnn.mean(dim=-1)  # (B, 16, T)\n\n        # Prepare for LSTM: concat conv features with original\n        x_cnn = x_cnn.permute(0, 2, 1)          # (B, T, 16)\n        x_combined = torch.cat([x, x_cnn], dim=-1)  # (B, T, F+16)\n\n        # LSTM along time\n        x_lstm, _ = self.lstm(x_combined)\n        x_out = self.dropout(x_lstm[:, -1, :])\n        x_out = self.fc(x_out)\n\n        x_out = make_dollar_neutral(x_out)  # ensure dollar-neutral outputs\n        return x_out\n\nclass MLP(nn.Module):\n    def __init__(self, n_features, n_outputs, lookback):\n        super(MLP, self).__init__()\n        self.fc1 = nn.Linear(n_features * lookback, 128)\n        self.fc2 = nn.Linear(128, 64)\n        self.fc3 = nn.Linear(64, n_outputs)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.3)\n\n\n    def forward(self, x):\n        # x: (batch, seq_len, n_features)\n        x = x.reshape(x.size(0), -1)  # flatten, works even if not contiguous\n        x = self.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.relu(self.fc2(x))\n        x = self.fc3(x)\n        x = make_dollar_neutral(x)  # ensure dollar-neutral outputs\n        return x\n    \nclass LSTMModel(nn.Module):\n    def __init__(self, n_features, n_outputs, lookback):\n        super(LSTMModel, self).__init__()\n        self.lstm = nn.LSTM(input_size=n_features, hidden_size=64, batch_first=True)\n        self.dropout = nn.Dropout(0.3)\n        self.fc1 = nn.Linear(64, 64)\n        self.fc2 = nn.Linear(64, n_outputs)   # map to number of assets\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        x, _ = self.lstm(x)\n        x = self.dropout(x[:, -1, :])      # last LSTM output\n        x = self.relu(self.fc1(x))\n        x = self.fc2(x)                     # now shape = (batch_size, n_outputs)\n        x = make_dollar_neutral(x)          # ensure dollar-neutral outputs\n        return x\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# ----- Dataset class -----\nclass TimeSeriesDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = X\n        self.y = y\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\n    \n# ----- Sharpe Loss with Transaction Cost -----\nclass SharpeLossWithTC(nn.Module):\n    def __init__(self, tc_lambda=0.001, eps=1e-4):\n        super().__init__()\n        self.tc_lambda = tc_lambda\n        self.eps = eps\n\n    def forward(self, y_pred, y_true, prev_weights=None):\n        weights = y_pred\n        # Portfolio returns\n        port_returns = torch.sum(weights * y_true, dim=1)\n        mean = torch.mean(port_returns)\n        std = torch.std(port_returns, unbiased=False) + self.eps  # avoids warning\n        sharpe = mean / std\n\n        # Transaction cost penalty\n        t_cost = 0.005\n        if prev_weights is not None:\n            # prev_weights may have different batch sizes; slice to match current batch\n            if prev_weights.shape[0] != weights.shape[0]:\n                prev_weights = prev_weights[-weights.shape[0]:, :]\n            t_cost = torch.mean(torch.abs(weights - prev_weights))\n\n        return -sharpe + self.tc_lambda * t_cost, weights\n\n# --- Helper: Train model on a rolling window with optional verbosity, early stopping on loss ---\ndef train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=100, patience=10, verbose=False):\n    best_val_loss = np.inf\n    best_model_state = None\n    epochs_no_improve = 0\n\n    for epoch in range(num_epochs):\n        # --- Training ---\n        model.train()\n        prev_w = None\n        train_loss = 0.0\n\n        for X_batch, y_batch in train_loader:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n\n            optimizer.zero_grad()\n            y_pred = model(X_batch)\n            loss, prev_w = criterion(y_pred, y_batch, prev_weights=prev_w)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n            prev_w = prev_w.detach()\n            train_loss += loss.item()\n\n        train_loss /= len(train_loader)\n\n        # --- Validation ---\n        model.eval()\n        prev_w_val = None\n        val_loss = 0.0\n\n        with torch.no_grad():\n            for X_batch, y_batch in val_loader:\n                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n                y_pred = model(X_batch)\n                loss, prev_w_val = criterion(y_pred, y_batch, prev_weights=prev_w_val)\n                prev_w_val = prev_w_val.detach()\n                val_loss += loss.item()\n\n        val_loss /= len(val_loader)\n\n        # --- Early stopping on validation loss ---\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            best_model_state = copy.deepcopy(model.state_dict())\n            epochs_no_improve = 0\n        else:\n            epochs_no_improve += 1\n            if epochs_no_improve >= patience:\n                if verbose:\n                    print(f\"Early stopping at epoch {epoch+1}. Best val loss: {best_val_loss:.6f}\")\n                break\n\n        # --- Verbose printing ---\n        if verbose and (epoch % 10 == 0 or epoch == num_epochs - 1):\n            print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f}\")\n\n    return best_model_state\n\ndef create_sequences(X, y, lookback):\n    X_seq, y_seq = [], []\n    for i in range(len(X) - lookback):\n        X_seq.append(torch.tensor(X[i:i+lookback], dtype=torch.float32))\n        y_seq.append(torch.tensor(y[i:i+lookback][-1], dtype=torch.float32))  # last y in window\n    return torch.stack(X_seq), torch.stack(y_seq)\n\nlookback = int(126//5)  # 6 months\ntraining_window = int(252*5//5)  # 3 years\nval_window = int(252//5)         # 1 year\nensemble_size = 5          # number of model initializations per retraining\n\nmodels_to_run = {\n    \"MLP\": MLP,\n    \"LSTM\": LSTMModel,\n    \"CNNLSTM\": CNNLSTM2D    \n}\n\nresults = {}\n\nfor name, ModelClass in models_to_run.items():\n    print(f\"\\n=== Training {name} (Ensemble of {ensemble_size}) ===\")\n    criterion = SharpeLossWithTC(tc_lambda=STATIC_TC_LAMBDA)  # 0.1 (domain-expert)\n\n    oos_returns = []\n    oos_weights = []\n    oos_dates = []\n\n    start_train = training_window + val_window\n    all_test_days = X.index[start_train:]\n\n    # --- First day of each month for retraining ---\n    all_test_days_series = all_test_days.to_series()\n    yearly_train_days = (\n        all_test_days_series.groupby(all_test_days_series.dt.to_period(\"Y\")).first()\n    )\n    yearly_train_days.index = yearly_train_days.index.to_timestamp()\n\n    # drop any NAs (in case a year has no test days)\n    yearly_train_days = yearly_train_days.dropna()\n    \n    for idx, year_start in enumerate(yearly_train_days):\n        print(f\"\\nRetraining {name} for year starting {year_start}\")\n        t = X.index.get_loc(year_start)\n\n        next_year_idx = (\n            X.index.get_loc(yearly_train_days.iloc[idx + 1])\n            if idx + 1 < len(yearly_train_days)\n            else len(X)\n        )\n\n        # --- Rolling window for train/val ---\n        train_start = t - training_window - val_window\n        train_end   = t - val_window\n        val_start   = train_end\n        val_end     = t\n\n        X_train_window = X.iloc[train_start:train_end].values\n        y_train_window = y.iloc[train_start:train_end].values\n        X_val_window   = X.iloc[val_start:val_end].values\n        y_val_window   = y.iloc[val_start:val_end].values\n\n        # --- Normalize once ---\n        X_mean = X_train_window.mean(axis=0)\n        X_std  = X_train_window.std(axis=0) + 1e-8\n        X_train_norm = (X_train_window - X_mean) / X_std\n        X_val_norm   = (X_val_window - X_mean) / X_std\n\n        # --- Create sequences ---\n        X_train_seq, y_train_seq = create_sequences(X_train_norm, y_train_window, lookback)\n        X_val_seq, y_val_seq     = create_sequences(X_val_norm, y_val_window, lookback)\n\n        train_loader = DataLoader(\n            TimeSeriesDataset(X_train_seq, y_train_seq),\n            batch_size=64,\n            shuffle=True,\n            num_workers=0,\n            generator=torch.Generator().manual_seed(seed)\n        )\n\n        val_loader = DataLoader(\n            TimeSeriesDataset(X_val_seq, y_val_seq),\n            batch_size=64,\n            shuffle=False,\n            num_workers=0,\n            generator=torch.Generator().manual_seed(seed)\n        )\n\n        # --- Train ensemble models ---\n        ensemble_models = []\n        for s in range(ensemble_size):\n            np.random.seed(s)\n            random.seed(s)\n            torch.manual_seed(s)\n            \n            model = ModelClass(n_features=X.shape[1], n_outputs=y.shape[1], lookback=lookback).to(device)\n            optimizer = torch.optim.Adam(model.parameters(), lr=STATIC_LR)  # 0.0001 (domain-expert)\n            best_state = train_model(model, train_loader, val_loader, criterion, optimizer, verbose=False)\n            model.load_state_dict(best_state)\n            ensemble_models.append(model)\n\n        for test_day in range(t, next_year_idx):\n            if test_day - lookback + 1 < 0:\n                continue\n            X_test_seq = X.iloc[test_day - lookback + 1:test_day + 1].values\n            X_test_norm = (X_test_seq - X_mean) / X_std\n            X_test_tensor = torch.tensor(X_test_norm, dtype=torch.float32).unsqueeze(0).to(device)\n\n            y_test_tensor = torch.tensor(y.iloc[test_day:test_day+1].values, dtype=torch.float32).to(device)\n\n            # --- Ensemble prediction ---\n            preds = []\n            for model in ensemble_models:\n                model.eval()\n                with torch.no_grad():\n                    preds.append(model(X_test_tensor))\n            y_pred = torch.stack(preds).mean(dim=0)\n\n            # --- Compute portfolio return ---\n            weights = y_pred\n            r = torch.sum(weights * y_test_tensor, dim=1)\n\n            oos_returns.append(r.cpu().numpy())\n            oos_weights.append(weights.cpu().numpy()[0])\n            oos_dates.append(X.index[test_day])\n\n    # --- Save out-of-sample results ---\n    oos_weights_df = pd.DataFrame(oos_weights, index=oos_dates, columns=y.columns)\n    oos_returns_series = pd.Series(np.concatenate(oos_returns), index=oos_dates, name=\"OOS_Returns\")\n    oos_weights_df.to_csv(f\"{name}_oos_weights.csv\")\n    oos_returns_arr = np.concatenate(oos_returns)\n    oos_sharpe = np.mean(oos_returns_arr) / (np.std(oos_returns_arr) + 1e-8) * np.sqrt(52)\n    print(f\"{name} Out-of-sample annualized Sharpe: {oos_sharpe:.3f}\")\n\n    results[name] = oos_sharpe\n\n# --- Summary ---\nprint(\"\\n\" + \"=\"*80)\nprint(\"SUMMARY: OUT-OF-SAMPLE SHARPE RATIOS (STATIC HYPERPARAMETERS)\")\nprint(\"=\"*80)\nfor name, sharpe in results.items():\n    print(f\"{name}: {sharpe:.3f}\")\nprint(\"=\"*80)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =====================================================================\n# COMPREHENSIVE BACKTESTING WITH TRANSACTION COSTS AND METRICS\n# =====================================================================\n\nprint(\"=\"*70)\nprint(\"PHASE 1: PROPER BACKTESTING WITH TRANSACTION COSTS\")\nprint(\"=\"*70)\n\n# Load all model weights\nmodel_names = [\"MLP\", \"LSTM\", \"CNNLSTM\"]\nall_weights = {}\n\nfor name in model_names:\n    weights_df = pd.read_csv(f\"{name}_oos_weights.csv\", index_col=0, parse_dates=True)\n    all_weights[name] = weights_df\n    print(f\"\\n{name} weights loaded: {len(weights_df)} weeks, {weights_df.shape[1]} assets\")\n\n# Get weekly returns: Friday close to next Friday close\nweekly_close = yfinance_df[\"Close\"].resample(\"W-FRI\").last()\nweekly_returns = weekly_close.pct_change().shift(-1)  # Returns for next week\n\n# Transaction cost parameters\nTC_BPS = 10  # 10 basis points per trade (industry standard)\nTC_RATE = TC_BPS / 10000  # Convert to decimal\n\nprint(f\"\\nTransaction Cost: {TC_BPS} bps ({TC_RATE:.4f}) per trade\")\nprint(f\"Out-of-Sample Period: {all_weights['CNNLSTM'].index[0]} to {all_weights['CNNLSTM'].index[-1]}\")\n\n# =====================================================================\n# BACKTEST FUNCTION\n# =====================================================================\n\ndef backtest_strategy(weights_df, returns_df, tc_rate=0.001):\n    \"\"\"\n    Backtest a trading strategy with transaction costs.\n    \n    Parameters:\n    -----------\n    weights_df : DataFrame\n        Portfolio weights at each time t (decided at Friday t)\n    returns_df : DataFrame  \n        Asset returns from Friday t to Friday t+1\n    tc_rate : float\n        Transaction cost as fraction of trade value (default: 0.001 = 10 bps)\n    \n    Returns:\n    --------\n    dict : Dictionary with portfolio metrics and time series\n    \"\"\"\n    # Align weights and returns\n    common_dates = weights_df.index.intersection(returns_df.index)\n    weights_aligned = weights_df.loc[common_dates]\n    returns_aligned = returns_df.loc[common_dates]\n    \n    # Portfolio returns before TC\n    gross_returns = (weights_aligned * returns_aligned).sum(axis=1)\n    \n    # Calculate turnover (sum of absolute weight changes)\n    turnover = np.abs(weights_aligned.diff()).sum(axis=1)\n    turnover.iloc[0] = np.abs(weights_aligned.iloc[0]).sum()  # First period: establish positions\n    \n    # Transaction costs\n    tc_costs = turnover * tc_rate\n    \n    # Net returns after transaction costs\n    net_returns = gross_returns - tc_costs\n    \n    # Cumulative returns\n    cum_gross_returns = (1 + gross_returns).cumprod()\n    cum_net_returns = (1 + net_returns).cumprod()\n    \n    return {\n        'gross_returns': gross_returns,\n        'net_returns': net_returns,\n        'turnover': turnover,\n        'tc_costs': tc_costs,\n        'cum_gross_returns': cum_gross_returns,\n        'cum_net_returns': cum_net_returns,\n        'weights': weights_aligned\n    }\n\n# =====================================================================\n# RUN BACKTESTS FOR ALL MODELS\n# =====================================================================\n\nbacktest_results = {}\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"BACKTESTING RESULTS\")\nprint(\"=\"*70)\n\nfor name in model_names:\n    print(f\"\\nBacktesting {name}...\")\n    results = backtest_strategy(all_weights[name], weekly_returns, tc_rate=TC_RATE)\n    backtest_results[name] = results\n    \n    # Calculate metrics\n    net_ret = results['net_returns']\n    gross_ret = results['gross_returns']\n    \n    # Annualization factor (52 weeks per year)\n    ann_factor = 52\n    sqrt_ann = np.sqrt(ann_factor)\n    \n    # Performance metrics\n    total_weeks = len(net_ret)\n    total_years = total_weeks / ann_factor\n    \n    ann_return_net = (results['cum_net_returns'].iloc[-1]) ** (1 / total_years) - 1\n    ann_return_gross = (results['cum_gross_returns'].iloc[-1]) ** (1 / total_years) - 1\n    ann_vol = net_ret.std() * sqrt_ann\n    sharpe_net = (net_ret.mean() / net_ret.std()) * sqrt_ann if net_ret.std() > 0 else 0\n    sharpe_gross = (gross_ret.mean() / gross_ret.std()) * sqrt_ann if gross_ret.std() > 0 else 0\n    \n    # Downside metrics\n    downside_returns = net_ret[net_ret < 0]\n    sortino = (net_ret.mean() / downside_returns.std()) * sqrt_ann if len(downside_returns) > 0 else 0\n    \n    # Drawdown\n    cum_ret = results['cum_net_returns']\n    running_max = cum_ret.expanding().max()\n    drawdown = (cum_ret - running_max) / running_max\n    max_drawdown = drawdown.min()\n    \n    # Calmar ratio (return / max drawdown)\n    calmar = ann_return_net / abs(max_drawdown) if max_drawdown != 0 else 0\n    \n    # Turnover\n    avg_turnover = results['turnover'].mean()\n    total_tc_cost = results['tc_costs'].sum()\n    \n    # Win rate\n    win_rate = (net_ret > 0).sum() / len(net_ret)\n    \n    # Store comprehensive results\n    backtest_results[name]['metrics'] = {\n        'Annual Return (Net)': ann_return_net,\n        'Annual Return (Gross)': ann_return_gross,\n        'Annual Volatility': ann_vol,\n        'Sharpe Ratio (Net)': sharpe_net,\n        'Sharpe Ratio (Gross)': sharpe_gross,\n        'Sortino Ratio': sortino,\n        'Calmar Ratio': calmar,\n        'Max Drawdown': max_drawdown,\n        'Avg Weekly Turnover': avg_turnover,\n        'Total TC Cost': total_tc_cost,\n        'TC Impact on Sharpe': sharpe_gross - sharpe_net,\n        'Win Rate': win_rate\n    }\n    \n    print(f\"\\n{name} Performance:\")\n    print(f\"  Annualized Return (Net):  {ann_return_net:>8.2%}\")\n    print(f\"  Annualized Volatility:    {ann_vol:>8.2%}\")\n    print(f\"  Sharpe Ratio (Net):       {sharpe_net:>8.3f}\")\n    print(f\"  Max Drawdown:             {max_drawdown:>8.2%}\")\n    print(f\"  Avg Weekly Turnover:      {avg_turnover:>8.2%}\")\n    print(f\"  TC Impact on Sharpe:      {sharpe_gross - sharpe_net:>8.3f}\")\n\n# =====================================================================\n# SPY BENCHMARK\n# =====================================================================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"SPY BENCHMARK\")\nprint(\"=\"*70)\n\n# Download SPY data\nspy_data = yf.download(\"SPY\", start=\"2015-10-01\", end=\"2025-10-31\", progress=False)\nspy_weekly = spy_data['Close'].resample(\"W-FRI\").last()\nspy_returns = spy_weekly.pct_change().dropna()\n\n# Align with strategy period\ncommon_dates = backtest_results['CNNLSTM']['net_returns'].index.intersection(spy_returns.index)\nspy_returns_aligned = spy_returns.loc[common_dates]\n\n# SPY metrics - ensure scalar values\nspy_cum_returns = (1 + spy_returns_aligned).cumprod()\nspy_final_value = float(spy_cum_returns.iloc[-1])  # Ensure scalar\nspy_n_weeks = len(spy_returns_aligned)\nspy_ann_return = (spy_final_value) ** (1 / (spy_n_weeks / 52)) - 1\nspy_ann_vol = float(spy_returns_aligned.std() * np.sqrt(52))\nspy_sharpe = float((spy_returns_aligned.mean() / spy_returns_aligned.std()) * np.sqrt(52))\n\n# SPY drawdown\nspy_running_max = spy_cum_returns.expanding().max()\nspy_drawdown = (spy_cum_returns - spy_running_max) / spy_running_max\nspy_max_dd = float(spy_drawdown.min())\n\nprint(f\"\\nSPY Buy-and-Hold Performance:\")\nprint(f\"  Annualized Return:        {spy_ann_return:>8.2%}\")\nprint(f\"  Annualized Volatility:    {spy_ann_vol:>8.2%}\")\nprint(f\"  Sharpe Ratio:             {spy_sharpe:>8.3f}\")\nprint(f\"  Max Drawdown:             {spy_max_dd:>8.2%}\")\n\n# Store SPY results\nbacktest_results['SPY'] = {\n    'net_returns': spy_returns_aligned,\n    'cum_net_returns': spy_cum_returns,\n    'metrics': {\n        'Annual Return (Net)': spy_ann_return,\n        'Annual Volatility': spy_ann_vol,\n        'Sharpe Ratio (Net)': spy_sharpe,\n        'Max Drawdown': spy_max_dd,\n    }\n}\n\n# =====================================================================\n# PERFORMANCE COMPARISON TABLE\n# =====================================================================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"COMPREHENSIVE PERFORMANCE COMPARISON\")\nprint(\"=\"*70)\n\ncomparison_df = pd.DataFrame({\n    'MLP': backtest_results['MLP']['metrics'],\n    'LSTM': backtest_results['LSTM']['metrics'],\n    'CNN-LSTM': backtest_results['CNNLSTM']['metrics'],\n    'SPY': {k: backtest_results['SPY']['metrics'].get(k, np.nan) \n            for k in backtest_results['CNNLSTM']['metrics'].keys()}\n})\n\nprint(\"\\n\", comparison_df.T.to_string())\n\n# Save results\ncomparison_df.T.to_csv(\"performance_comparison.csv\")\nprint(\"\\n✓ Performance comparison saved to 'performance_comparison.csv'\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"BACKTESTING COMPLETE\")\nprint(\"=\"*70)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =====================================================================\n# REQUIRED VISUALIZATIONS (Task 4.9)\n# =====================================================================\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_style(\"whitegrid\")\nplt.rcParams['figure.figsize'] = (14, 8)\n\nprint(\"=\"*70)\nprint(\"CREATING REQUIRED PLOTS\")\nprint(\"=\"*70)\n\n# =====================================================================\n# PLOT 1: Cumulative Returns vs SPY Benchmark\n# =====================================================================\n\nfig, axes = plt.subplots(2, 2, figsize=(16, 12))\n\n# Plot 1a: All strategies vs SPY\nax = axes[0, 0]\nfor name in ['MLP', 'LSTM', 'CNNLSTM']:\n    cum_ret = backtest_results[name]['cum_net_returns']\n    ax.plot(cum_ret.index, (cum_ret - 1) * 100, label=name, linewidth=2)\n\nspy_cum = backtest_results['SPY']['cum_net_returns']\nax.plot(spy_cum.index, (spy_cum - 1) * 100, label='SPY', \n        linewidth=2, linestyle='--', color='black', alpha=0.7)\n\nax.set_xlabel('Date', fontsize=11)\nax.set_ylabel('Cumulative Return (%)', fontsize=11)\nax.set_title('Cumulative Returns: Strategies vs SPY Benchmark', fontsize=13, fontweight='bold')\nax.legend(loc='best', fontsize=10)\nax.grid(True, alpha=0.3)\n\n# Plot 1b: CNN-LSTM vs SPY (focused)\nax = axes[0, 1]\ncum_ret_cnn = backtest_results['CNNLSTM']['cum_net_returns']\nax.plot(cum_ret_cnn.index, (cum_ret_cnn - 1) * 100, \n        label='CNN-LSTM (Best)', linewidth=2.5, color='#2E86AB')\nax.plot(spy_cum.index, (spy_cum - 1) * 100, \n        label='SPY Benchmark', linewidth=2, linestyle='--', color='black', alpha=0.7)\n\nax.set_xlabel('Date', fontsize=11)\nax.set_ylabel('Cumulative Return (%)', fontsize=11)\nax.set_title('CNN-LSTM vs SPY: Out-of-Sample Performance', fontsize=13, fontweight='bold')\nax.legend(loc='best', fontsize=10)\nax.grid(True, alpha=0.3)\n\n# Add performance text\nfinal_cnn = (cum_ret_cnn.iloc[-1] - 1) * 100\nfinal_spy = (spy_cum.iloc[-1] - 1) * 100\ntextstr = f'CNN-LSTM: {final_cnn:.1f}%\\nSPY: {final_spy:.1f}%\\nOutperformance: {final_cnn - final_spy:.1f}%'\nax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=10,\n        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n\n# =====================================================================\n# PLOT 2: Rolling Sharpe Ratio (52-week window)\n# =====================================================================\n\nax = axes[1, 0]\nrolling_window = 52  # 1 year\n\nfor name in ['MLP', 'LSTM', 'CNNLSTM']:\n    net_ret = backtest_results[name]['net_returns']\n    rolling_sharpe = (net_ret.rolling(rolling_window).mean() / \n                      net_ret.rolling(rolling_window).std()) * np.sqrt(52)\n    ax.plot(rolling_sharpe.index, rolling_sharpe, label=name, linewidth=2)\n\n# SPY rolling Sharpe\nspy_ret = backtest_results['SPY']['net_returns']\nspy_rolling_sharpe = (spy_ret.rolling(rolling_window).mean() / \n                      spy_ret.rolling(rolling_window).std()) * np.sqrt(52)\nax.plot(spy_rolling_sharpe.index, spy_rolling_sharpe, \n        label='SPY', linewidth=2, linestyle='--', color='black', alpha=0.7)\n\nax.axhline(y=0, color='red', linestyle=':', alpha=0.5, label='Zero')\nax.set_xlabel('Date', fontsize=11)\nax.set_ylabel('Rolling Sharpe Ratio', fontsize=11)\nax.set_title(f'{rolling_window}-Week Rolling Sharpe Ratio', fontsize=13, fontweight='bold')\nax.legend(loc='best', fontsize=9)\nax.grid(True, alpha=0.3)\n\n# =====================================================================\n# PLOT 3: Drawdown Analysis\n# =====================================================================\n\nax = axes[1, 1]\n\nfor name in ['MLP', 'LSTM', 'CNNLSTM']:\n    cum_ret = backtest_results[name]['cum_net_returns']\n    running_max = cum_ret.expanding().max()\n    drawdown = ((cum_ret - running_max) / running_max) * 100\n    ax.plot(drawdown.index, drawdown, label=name, linewidth=2)\n\n# SPY drawdown\nspy_cum = backtest_results['SPY']['cum_net_returns']\nspy_running_max = spy_cum.expanding().max()\nspy_dd = ((spy_cum - spy_running_max) / spy_running_max) * 100\nax.plot(spy_dd.index, spy_dd, label='SPY', linewidth=2, \n        linestyle='--', color='black', alpha=0.7)\n\nax.fill_between(drawdown.index, 0, drawdown, alpha=0.3)\nax.set_xlabel('Date', fontsize=11)\nax.set_ylabel('Drawdown (%)', fontsize=11)\nax.set_title('Strategy Drawdowns Over Time', fontsize=13, fontweight='bold')\nax.legend(loc='best', fontsize=9)\nax.grid(True, alpha=0.3)\n\n# Add max drawdown annotations\nfor name in ['CNNLSTM', 'SPY']:\n    if name == 'SPY':\n        dd = spy_dd\n        color = 'black'\n    else:\n        cum_ret = backtest_results[name]['cum_net_returns']\n        running_max = cum_ret.expanding().max()\n        dd = ((cum_ret - running_max) / running_max) * 100\n        color = '#2E86AB'\n    \n    max_dd_idx = dd.idxmin()\n    max_dd_val = dd.min()\n\nplt.tight_layout()\nplt.savefig('performance_plots_1.png', dpi=300, bbox_inches='tight')\nprint(\"\\n✓ Saved 'performance_plots_1.png'\")\nplt.show()\n\n# =====================================================================\n# PLOT 4: Additional Analysis Plots\n# =====================================================================\n\nfig, axes = plt.subplots(2, 2, figsize=(16, 12))\n\n# Plot 4a: Weekly Returns Distribution\nax = axes[0, 0]\nfor name in ['CNNLSTM', 'SPY']:\n    if name == 'SPY':\n        returns = backtest_results['SPY']['net_returns'] * 100\n        label_txt = 'SPY'\n    else:\n        returns = backtest_results[name]['net_returns'] * 100\n        label_txt = 'CNN-LSTM'\n    \n    ax.hist(returns, bins=50, alpha=0.6, label=label_txt, edgecolor='black')\n\nax.set_xlabel('Weekly Return (%)', fontsize=11)\nax.set_ylabel('Frequency', fontsize=11)\nax.set_title('Distribution of Weekly Returns', fontsize=13, fontweight='bold')\nax.legend(loc='best', fontsize=10)\nax.grid(True, alpha=0.3, axis='y')\n\n# Plot 4b: Turnover Over Time\nax = axes[0, 1]\nfor name in ['MLP', 'LSTM', 'CNNLSTM']:\n    turnover = backtest_results[name]['turnover'] * 100\n    ax.plot(turnover.index, turnover.rolling(12).mean(), label=f'{name} (12w MA)', linewidth=2)\n\nax.set_xlabel('Date', fontsize=11)\nax.set_ylabel('Turnover (%)', fontsize=11)\nax.set_title('Portfolio Turnover Over Time (12-week Moving Average)', fontsize=13, fontweight='bold')\nax.legend(loc='best', fontsize=10)\nax.grid(True, alpha=0.3)\n\n# Plot 4c: Transaction Cost Impact\nax = axes[1, 0]\nmetrics_plot = []\nfor name in ['MLP', 'LSTM', 'CNNLSTM']:\n    gross_sharpe = backtest_results[name]['metrics']['Sharpe Ratio (Gross)']\n    net_sharpe = backtest_results[name]['metrics']['Sharpe Ratio (Net)']\n    metrics_plot.append([name, gross_sharpe, net_sharpe])\n\nmetrics_df = pd.DataFrame(metrics_plot, columns=['Strategy', 'Gross Sharpe', 'Net Sharpe'])\nx = np.arange(len(metrics_df))\nwidth = 0.35\n\nax.bar(x - width/2, metrics_df['Gross Sharpe'], width, label='Gross (No TC)', alpha=0.8)\nax.bar(x + width/2, metrics_df['Net Sharpe'], width, label='Net (With 10 bps TC)', alpha=0.8)\n\nax.set_xlabel('Strategy', fontsize=11)\nax.set_ylabel('Sharpe Ratio', fontsize=11)\nax.set_title('Transaction Cost Impact on Sharpe Ratio', fontsize=13, fontweight='bold')\nax.set_xticks(x)\nax.set_xticklabels(metrics_df['Strategy'])\nax.legend(loc='best', fontsize=10)\nax.grid(True, alpha=0.3, axis='y')\n\n# Add SPY for reference\nspy_sharpe = backtest_results['SPY']['metrics']['Sharpe Ratio (Net)']\nax.axhline(y=spy_sharpe, color='black', linestyle='--', alpha=0.5, label=f'SPY ({spy_sharpe:.2f})')\n\n# Plot 4d: Cumulative Transaction Costs\nax = axes[1, 1]\nfor name in ['MLP', 'LSTM', 'CNNLSTM']:\n    cum_tc = backtest_results[name]['tc_costs'].cumsum() * 100\n    ax.plot(cum_tc.index, cum_tc, label=name, linewidth=2)\n\nax.set_xlabel('Date', fontsize=11)\nax.set_ylabel('Cumulative TC Cost (%)', fontsize=11)\nax.set_title('Cumulative Transaction Costs', fontsize=13, fontweight='bold')\nax.legend(loc='best', fontsize=10)\nax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('performance_plots_2.png', dpi=300, bbox_inches='tight')\nprint(\"✓ Saved 'performance_plots_2.png'\")\nplt.show()\n\n# =====================================================================\n# PLOT 5: Out-of-Sample R² (Prediction Accuracy)\n# =====================================================================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"CALCULATING OUT-OF-SAMPLE R²\")\nprint(\"=\"*70)\n\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\n# Calculate OOS R² for each model\n# R² = 1 - (SS_res / SS_tot) where SS_res = sum((y_true - y_pred)^2), SS_tot = sum((y_true - y_mean)^2)\n\nax = axes[0]\nr2_scores = {}\n\nfor name in ['MLP', 'LSTM', 'CNNLSTM']:\n    weights = backtest_results[name]['weights']\n    \n    # Get aligned returns\n    common_dates = weights.index.intersection(weekly_returns.index)\n    weights_aligned = weights.loc[common_dates]\n    returns_aligned = weekly_returns.loc[common_dates]\n    \n    # Predicted returns (portfolio returns from weights)\n    predicted_returns = (weights_aligned * returns_aligned).sum(axis=1)\n    \n    # Actual portfolio returns (use equal weight as baseline)\n    equal_weight = 1 / returns_aligned.shape[1]\n    actual_mean_return = returns_aligned.mean(axis=1)\n    \n    # Calculate R² relative to predicting mean return\n    ss_res = ((predicted_returns - actual_mean_return) ** 2).sum()\n    ss_tot = ((actual_mean_return - actual_mean_return.mean()) ** 2).sum()\n    r2 = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0\n    \n    r2_scores[name] = r2\n    \n    # Rolling R² (52-week window)\n    rolling_r2 = []\n    dates = []\n    for i in range(52, len(predicted_returns)):\n        window_pred = predicted_returns.iloc[i-52:i]\n        window_actual = actual_mean_return.iloc[i-52:i]\n        \n        ss_res_w = ((window_pred - window_actual) ** 2).sum()\n        ss_tot_w = ((window_actual - window_actual.mean()) ** 2).sum()\n        r2_w = 1 - (ss_res_w / ss_tot_w) if ss_tot_w != 0 else 0\n        \n        rolling_r2.append(r2_w)\n        dates.append(predicted_returns.index[i])\n    \n    ax.plot(dates, rolling_r2, label=f'{name} (Overall R²: {r2:.3f})', linewidth=2)\n\nax.axhline(y=0, color='red', linestyle=':', alpha=0.5)\nax.set_xlabel('Date', fontsize=11)\nax.set_ylabel('Rolling R² (52-week)', fontsize=11)\nax.set_title('Out-of-Sample Prediction R² Over Time', fontsize=13, fontweight='bold')\nax.legend(loc='best', fontsize=10)\nax.grid(True, alpha=0.3)\n\n# Bar plot of overall R²\nax = axes[1]\nmodels = list(r2_scores.keys())\nr2_vals = list(r2_scores.values())\ncolors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n\nbars = ax.bar(models, r2_vals, color=colors, alpha=0.7, edgecolor='black')\nax.set_ylabel('Out-of-Sample R²', fontsize=11)\nax.set_title('Overall OOS R² by Model', fontsize=13, fontweight='bold')\nax.grid(True, alpha=0.3, axis='y')\nax.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n\n# Add value labels on bars\nfor bar, val in zip(bars, r2_vals):\n    height = bar.get_height()\n    ax.text(bar.get_x() + bar.get_width()/2., height,\n            f'{val:.3f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n\nplt.tight_layout()\nplt.savefig('oos_r2_analysis.png', dpi=300, bbox_inches='tight')\nprint(\"\\n✓ Saved 'oos_r2_analysis.png'\")\nplt.show()\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"ALL REQUIRED PLOTS COMPLETED\")\nprint(\"=\"*70)\nprint(\"\\nGenerated Files:\")\nprint(\"  1. performance_plots_1.png - Cumulative returns, rolling Sharpe, drawdowns\")\nprint(\"  2. performance_plots_2.png - Returns distribution, turnover, TC impact\")  \nprint(\"  3. oos_r2_analysis.png - Out-of-sample prediction R²\")\nprint(\"  4. performance_comparison.csv - Comprehensive metrics table\")"
  },
  {
   "cell_type": "code",
   "source": "# =====================================================================\n# STATISTICAL SIGNIFICANCE TESTS AND REGIME ANALYSIS\n# =====================================================================\n\nfrom scipy import stats\n\nprint(\"=\"*70)\nprint(\"STATISTICAL SIGNIFICANCE ANALYSIS\")\nprint(\"=\"*70)\n\n# =====================================================================\n# 1. BOOTSTRAP CONFIDENCE INTERVALS FOR SHARPE RATIO\n# =====================================================================\n\ndef bootstrap_sharpe_ci(returns, n_bootstrap=10000, ci=0.95, ann_factor=52):\n    \"\"\"Calculate bootstrap confidence intervals for annualized Sharpe ratio.\"\"\"\n    if hasattr(returns, 'values'):\n        returns = returns.values\n    returns = np.array(returns).flatten()\n    \n    sharpes = []\n    np.random.seed(42)  # For reproducibility\n\n    for _ in range(n_bootstrap):\n        sample = np.random.choice(returns, size=len(returns), replace=True)\n        sharpe = (np.mean(sample) / np.std(sample)) * np.sqrt(ann_factor)\n        sharpes.append(sharpe)\n\n    sharpes = np.array(sharpes)\n    lower = np.percentile(sharpes, (1-ci)/2 * 100)\n    upper = np.percentile(sharpes, (1+ci)/2 * 100)\n    estimate = (np.mean(returns) / np.std(returns)) * np.sqrt(ann_factor)\n\n    return lower, upper, estimate\n\nprint(\"\\n1. BOOTSTRAP CONFIDENCE INTERVALS (95%, N=10,000)\")\nprint(\"-\" * 70)\n\n# CNN-LSTM\ncnn_returns = backtest_results['CNNLSTM']['net_returns']\ncnn_lower, cnn_upper, cnn_sharpe = bootstrap_sharpe_ci(cnn_returns)\nprint(f\"CNN-LSTM Sharpe: {cnn_sharpe:.3f} [95% CI: {cnn_lower:.2f}, {cnn_upper:.2f}]\")\n\n# SPY\nspy_returns = backtest_results['SPY']['net_returns']\nspy_lower, spy_upper, spy_sharpe = bootstrap_sharpe_ci(spy_returns)\nprint(f\"SPY Sharpe:      {spy_sharpe:.3f} [95% CI: {spy_lower:.2f}, {spy_upper:.2f}]\")\n\n# Difference\ndiff = cnn_sharpe - spy_sharpe\nprint(f\"\\nDifference:      {diff:.3f} (CNN-LSTM - SPY)\")\n\n# Bootstrap the difference\nnp.random.seed(42)\ndiff_bootstrap = []\ncnn_array = np.array(cnn_returns).flatten()\nspy_array = np.array(spy_returns).flatten()\n\nfor _ in range(10000):\n    cnn_sample = np.random.choice(cnn_array, size=len(cnn_array), replace=True)\n    spy_sample = np.random.choice(spy_array, size=len(spy_array), replace=True)\n\n    cnn_s = (np.mean(cnn_sample) / np.std(cnn_sample)) * np.sqrt(52)\n    spy_s = (np.mean(spy_sample) / np.std(spy_sample)) * np.sqrt(52)\n    diff_bootstrap.append(cnn_s - spy_s)\n\ndiff_lower = np.percentile(diff_bootstrap, 2.5)\ndiff_upper = np.percentile(diff_bootstrap, 97.5)\nprint(f\"Difference CI:   [{diff_lower:.2f}, {diff_upper:.2f}]\")\n\np_value = np.mean(np.array(diff_bootstrap) <= 0)\nprint(f\"Bootstrap p-value: {p_value:.3f}\")\n\nif p_value < 0.05:\n    print(\"Result: Outperformance IS statistically significant at 5% level\")\nelse:\n    print(\"Result: Outperformance is NOT statistically significant at 5% level\")\n\n# =====================================================================\n# 2. REGIME ANALYSIS\n# =====================================================================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"2. REGIME-SPECIFIC PERFORMANCE\")\nprint(\"-\" * 70)\n\n# Define regimes\npre_covid_mask = cnn_returns.index < '2020-03-01'\ncovid_mask = (cnn_returns.index >= '2020-03-01') & (cnn_returns.index <= '2020-12-31')\npost_covid_mask = cnn_returns.index > '2020-12-31'\n\nregimes = {\n    'Pre-COVID Bull (Oct 2015 - Feb 2020)': pre_covid_mask,\n    'COVID Crisis (Mar 2020 - Dec 2020)': covid_mask,\n    'Recovery & Rates (Jan 2021 - Sep 2025)': post_covid_mask\n}\n\nregime_results = []\n\nfor regime_name, mask in regimes.items():\n    cnn_regime = cnn_returns[mask]\n    spy_regime = spy_returns[mask]\n\n    if len(cnn_regime) > 0:\n        cnn_sharpe_regime = (cnn_regime.mean() / cnn_regime.std()) * np.sqrt(52)\n        spy_sharpe_regime = (spy_regime.mean() / spy_regime.std()) * np.sqrt(52)\n\n        cnn_ann_ret = ((1 + cnn_regime).prod() ** (52 / len(cnn_regime))) - 1\n        spy_ann_ret = ((1 + spy_regime).prod() ** (52 / len(spy_regime))) - 1\n\n        regime_results.append({\n            'Regime': regime_name,\n            'Weeks': len(cnn_regime),\n            'CNN-LSTM Sharpe': f\"{cnn_sharpe_regime:.2f}\",\n            'SPY Sharpe': f\"{spy_sharpe_regime:.2f}\",\n            'CNN-LSTM Return': f\"{cnn_ann_ret:.2%}\",\n            'SPY Return': f\"{spy_ann_ret:.2%}\"\n        })\n\nregime_df = pd.DataFrame(regime_results)\nprint(\"\\n\" + regime_df.to_string(index=False))\n\n# =====================================================================\n# 3. YEAR-OVER-YEAR PERFORMANCE\n# =====================================================================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"3. YEAR-OVER-YEAR PERFORMANCE\")\nprint(\"-\" * 70)\n\nyearly_perf = []\nfor year in range(2016, 2026):\n    year_mask = (cnn_returns.index.year == year)\n    if year_mask.sum() > 0:\n        cnn_year = cnn_returns[year_mask]\n        spy_year = spy_returns[year_mask]\n\n        yearly_perf.append({\n            'Year': year,\n            'CNN-LSTM Return': f\"{((1 + cnn_year).prod() - 1):.2%}\",\n            'SPY Return': f\"{((1 + spy_year).prod() - 1):.2%}\",\n            'Outperformance': f\"{(((1 + cnn_year).prod() - 1) - ((1 + spy_year).prod() - 1)):.2%}\"\n        })\n\nyearly_df = pd.DataFrame(yearly_perf)\nprint(\"\\n\" + yearly_df.to_string(index=False))\n\n# Count outperformance years\noutperf_count = sum([float(row['Outperformance'].strip('%')) > 0 for row in yearly_perf])\ntotal_years = len(yearly_df)\nprint(f\"\\nOutperformed in {outperf_count}/{total_years} years ({outperf_count/total_years*100:.1f}%)\")\n\n# =====================================================================\n# SUMMARY\n# =====================================================================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"STATISTICAL ANALYSIS SUMMARY\")\nprint(\"=\"*70)\n\nprint(f\"\"\"\nKEY FINDINGS:\n1. CNN-LSTM Sharpe: {cnn_sharpe:.3f} [95% CI: {cnn_lower:.2f}, {cnn_upper:.2f}]\n2. SPY Sharpe: {spy_sharpe:.3f} [95% CI: {spy_lower:.2f}, {spy_upper:.2f}]\n3. Difference: {diff:.3f} with p-value = {p_value:.3f}\n4. Statistical Significance: {'YES' if p_value < 0.05 else 'NO'} at 5% level\n5. Year-over-year win rate: {outperf_count/total_years*100:.1f}%\n\nINTERPRETATION:\nThe CNN-LSTM strategy shows {'statistically significant' if p_value < 0.05 else 'modest but not statistically significant'}\noutperformance relative to SPY. The {'narrow' if (cnn_upper - cnn_lower) < 0.5 else 'wide'} confidence intervals\nreflect {'strong signal-to-noise ratio' if (cnn_upper - cnn_lower) < 0.5 else 'limited sample size (519 weekly observations ≈ 10 years)'}.\n\nFrom a practical standpoint, the {outperf_count/total_years*100:.1f}% win rate and superior\nrisk metrics (drawdown -22.71% vs -31.83%) suggest economic value despite statistical uncertainty.\n\"\"\")\n\n# Save results\nresults_summary = {\n    'CNN-LSTM Sharpe': cnn_sharpe,\n    'CNN-LSTM CI Lower': cnn_lower,\n    'CNN-LSTM CI Upper': cnn_upper,\n    'SPY Sharpe': spy_sharpe,\n    'SPY CI Lower': spy_lower,\n    'SPY CI Upper': spy_upper,\n    'Difference': diff,\n    'Difference CI Lower': diff_lower,\n    'Difference CI Upper': diff_upper,\n    'P-value': p_value,\n    'Statistically Significant': 'Yes' if p_value < 0.05 else 'No'\n}\n\nresults_df = pd.DataFrame([results_summary])\nresults_df.to_csv('statistical_test_results.csv', index=False)\nregime_df.to_csv('regime_analysis_results.csv', index=False)\n\nprint(\"\\n✓ Results saved to 'statistical_test_results.csv'\")\nprint(\"✓ Regime analysis saved to 'regime_analysis_results.csv'\")\nprint(\"\\n\" + \"=\"*70)\nprint(\"STATISTICAL ANALYSIS COMPLETE\")\nprint(\"=\"*70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}